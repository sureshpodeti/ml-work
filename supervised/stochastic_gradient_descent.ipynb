{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(m,n) = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.reshape(Y, (m,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, Y, theta):\n",
    "    return (1/(2*X.shape[0]))*np.sum(np.square(np.dot(X, theta)- Y), axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, Y, learning_rate=.00001, error=1e-9):\n",
    "    (m,n) = X.shape\n",
    "    X = np.hstack([np.ones((m,1)), X])\n",
    "    \n",
    "    theta = np.zeros((n+1,1))\n",
    "    \n",
    "    no_of_iter = 0\n",
    "    \n",
    "    \n",
    "    for _ in range(10000):\n",
    "        np.random.shuffle(X)\n",
    "        cost_prev = cost_function(X, Y, theta)\n",
    "        #update theta \n",
    "        theta -= learning_rate*(np.dot(X[:, :n+1].T, np.dot(X[:, :n+1], theta)-Y[:, :n+1]))\n",
    "        cost_curr = cost_function(X, Y, theta)\n",
    "        \n",
    "        if abs(cost_curr - cost_prev)<error:\n",
    "            break\n",
    "        no_of_iter += 1\n",
    "        \n",
    "        \n",
    "    return (no_of_iter, theta)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(no_of_iter, theta) = stochastic_gradient_descent(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.27686902e+01],\n",
       "       [-6.49651797e-03],\n",
       "       [-4.24501418e-02],\n",
       "       [-2.84383387e-02],\n",
       "       [ 9.82404903e-03],\n",
       "       [ 2.72115227e-02],\n",
       "       [-4.97348673e-02],\n",
       "       [ 8.21785839e-03],\n",
       "       [-2.90165931e-02],\n",
       "       [ 4.99233638e-03],\n",
       "       [ 3.05357821e-02],\n",
       "       [-4.30419430e-02],\n",
       "       [-8.66885116e-03],\n",
       "       [-2.83584635e-02]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.fit(X_train[:, 1:], Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.59512291])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98553508,  0.17462664,  1.08573161, -1.47837788,  3.29886575,\n",
       "        -0.6032804 , -2.71245504,  1.76788416, -1.92251667, -1.90603951,\n",
       "         0.74772011, -3.2343568 ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X, Y, learning_rate=.001, error=1e-9):\n",
    "    (m,n) = X.shape\n",
    "    X = np.hstack([np.ones((m,1)), X])\n",
    "    \n",
    "    theta = np.zeros((n+1,1))\n",
    "    \n",
    "    no_of_iter = 0\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(X)\n",
    "        cost_prev = cost_function(X, Y, theta)\n",
    "        #update theta \n",
    "        theta -= learning_rate*(np.dot(X.T, np.dot(X, theta)-Y))\n",
    "        cost_curr = cost_function(X, Y, theta)\n",
    "        \n",
    "        if abs(cost_curr - cost_prev)<error:\n",
    "            break\n",
    "        no_of_iter += 1\n",
    "        \n",
    "        \n",
    "    return (no_of_iter, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spodeti/Documents/environments/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/spodeti/Documents/environments/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in square\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-c8986bbc24b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mno_of_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-feede2c0fc0f>\u001b[0m in \u001b[0;36mbatch_gradient_descent\u001b[0;34m(X, Y, learning_rate, error)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mcost_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#update theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(no_of_iter, theta) = batch_gradient_descent(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.27720472e+01],\n",
       "       [ 1.26120504e-02],\n",
       "       [ 2.86860933e-03],\n",
       "       [-1.58295323e-02],\n",
       "       [ 2.14457479e-02],\n",
       "       [ 2.46032888e-02],\n",
       "       [ 7.57413580e-03],\n",
       "       [-3.55489519e-02],\n",
       "       [ 6.47933195e-03],\n",
       "       [-3.09540990e-03],\n",
       "       [ 5.48726159e-02],\n",
       "       [ 1.81861147e-02],\n",
       "       [-4.61563097e-03],\n",
       "       [ 2.25529947e-02]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
