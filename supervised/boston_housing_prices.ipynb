{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, preprocessing, model_selection\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "boston_data = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m, n) = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.reshape(boston_data.target, (m,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization, 0 mean and standard deviation\n",
    "X = preprocessing.scale(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m_train, n_train) = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, Y, theta):\n",
    "    return (1/2*X.shape[0])*np.sum(np.square(np.dot(X, theta)- Y), axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X, Y, learning_rate=.01, error=1e-9):\n",
    "    (m, n) = X.shape\n",
    "    # bias term column\n",
    "    X = np.hstack([np.ones((m,1)), X])\n",
    "    \n",
    "    theta = np.ones((n+1,1))\n",
    "    \n",
    "    no_of_iter = 0\n",
    "    \n",
    "    while True:\n",
    "        cost_prev = cost_function(X, Y, theta)\n",
    "        theta -= (learning_rate/m)*(np.dot(X.T, np.dot(X, theta)-Y))\n",
    "        cost_curr = cost_function(X, Y, theta)\n",
    "        \n",
    "        if abs(cost_prev-cost_curr)<error:\n",
    "            break\n",
    "        no_of_iter += 1\n",
    "        \n",
    "    return (theta, no_of_iter)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "(theta, no_of_iter) = batch_gradient_descent(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.50329436],\n",
       "       [-0.93440024],\n",
       "       [ 1.40610115],\n",
       "       [-0.02975095],\n",
       "       [ 0.58342958],\n",
       "       [-1.82662665],\n",
       "       [ 2.40631058],\n",
       "       [ 0.54764729],\n",
       "       [-2.93834915],\n",
       "       [ 2.88986609],\n",
       "       [-2.63457155],\n",
       "       [-1.8718151 ],\n",
       "       [ 0.65629164],\n",
       "       [-3.91190551]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.50329429])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93440087,  1.40610204, -0.02974763,  0.58342899, -1.82662689,\n",
       "         2.40630984,  0.54764786, -2.9383485 ,  2.88987738, -2.63458381,\n",
       "        -1.87181573,  0.65629176, -3.91190591]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
